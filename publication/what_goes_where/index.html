<html lang="en"><head>
    <meta charset="utf-8">

    <title>What Goes Where: Predicting Object Distributions From Above - Connor Greenwell</title>

    <link href="/css/style.css" rel="stylesheet" type="text/css" media="all">

    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-131229535-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</head><body>

<header><h1>Connor Greenwell</h1>

<nav>
<a href="/">About</a> &bull;
<a href="/publication/">Publications</a> &bull;

<a href="/pdfs/cv.pdf">CV</a>
</nav>
</header>

<hr>

<main>
<article>
    <header>
        <h1>What Goes Where: Predicting Object Distributions From Above</h1>
    </header>
    

<h2 id="abstract">Abstract</h2>

<p>In this work, we propose a cross-view learning approach,
in which images captured from a ground-level view are used
as weakly supervised annotations for interpreting overhead
imagery. The outcome is a convolutional neural network for
overhead imagery that is capable of predicting the type and
count of objects that are likely to be seen from a ground-level
perspective. We demonstrate our approach on a large dataset
of geotagged ground-level and overhead imagery and find that
our network captures semantically meaningful features, despite
being trained without manual annotations.</p>

<h2 id="paper-download">Paper Download</h2>

<figure>
<h2 id="bibtex">Bibtex</h2>

<pre><code>@inproceedings{greenwell2018objects,
  author = {Greenwell, Connor and Workman, Scott and Jacobs, Nathan},
  title = {What Goes Where: Predicting Object Distributions From Above},
  year = {2018},
  booktitle = {IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
  annotation = {CAREER}
}
</code></pre>



</figure>

</article>

</main>

<hr>

<footer>&copy; 2020 Connor Greenwell. All rights reserved.
</footer>

</body>
</html>
