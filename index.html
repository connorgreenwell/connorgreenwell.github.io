

<html lang="en-US">
<head>
	<meta name="generator" content="Hugo 0.18.1" />




<meta charset="utf-8">
<title>Connor Greenwell</title>
<meta name="description" content="Connor Greenwell">
<meta name="author" content="Connor Greenwell">


<meta name="viewport" content="width=device-width, initial-scale=1">


<link href="https://fonts.googleapis.com/css?family=Arvo|Roboto" rel="stylesheet">
<link rel="stylesheet" href="https://connorgreenwell.github.io/css/style.css">


<link rel="stylesheet" href="https://connorgreenwell.github.io/css/prism.css">

</head>
<body>



<header>
<h1><a href="https://connorgreenwell.github.io/">Connor Greenwell</a></h1>

<nav>
<ul>
    <li><a href="/pdfs/cv.pdf">CV</a></li>
    <li><a href="https://connorgreenwell.github.io/about">About Me</a></li>
    <li><a href="https://connorgreenwell.github.io/publications">Publications</a></li>
    <li><a href="https://connorgreenwell.github.io/blog">Blog</a></li>
    <li><a href="https://connorgreenwell.github.io/news">News</a></li>
</ul>
</nav>

</header>


<header>
    <h1>Recent Posts:</h1>
</header>









<article class="news">
<header>
    <h1>
        <small>
        <time datetime="2016-08-01T00:00:00Z">
            (2016-08-01)
        </time>
        </small>

        Started PhD at UK
    </h1>
</header>
</article>



<hr>




<article class="publications">

<header>
    <h1>
        <a href="https://connorgreenwell.github.io/publications/deeptransient/">A Fast Method for Estimating Transient Scene Attributes</a>
        (In WACV.)
    </h1>
</header>


<figure>
    <img src="https://connorgreenwell.github.io//img/deeptransient/splice.png">
</figure>


<p>
    Abstract We propose to use deep convolutional neural networks to estimate the transient attributes of a scene from a single image. Transient scene attributes describe both the objective conditions, such as the weather, time of day, and the season, and subjective properties of a scene, such as whether or not the scene seems busy. Recently, convolutional neural networks have been used to achieve state-of-the-art results for many vision problems, from object detection to scene classification, but have not previously been used for estimating transient attributes.
    
    (continued)
    
</p>

<footer>
    

    <p>
        submitted 
        <time datetime="2016-06-28T00:00:00Z">
            2016-06-28
        </time>
        in <a href="https://connorgreenwell.github.io/publications">publications</a>
    </p>
</footer>

</article>



<hr>






<article class="news">
<header>
    <h1>
        <small>
        <time datetime="2016-06-01T00:00:00Z">
            (2016-06-01)
        </time>
        </small>

        Graduated from UK CS Undergrad
    </h1>
</header>
</article>



<hr>




<article class="publications">

<header>
    <h1>
        <a href="https://connorgreenwell.github.io/publications/deepfocal/">DeepFocal: A Method for Direct Focal Length Estimation</a>
        (In ICIP.)
    </h1>
</header>


<figure>
    <img src="https://connorgreenwell.github.io//img/deepfocal/cartoon.png">
</figure>


<p>
    Abstract Estimating the focal length of an image is an important preprocessing step for many applications. Despite this, existing methods for single-view focal length estimation are limited in that they require particular geometric calibration objects, such as orthogonal vanishing points, co-planar circles, or a calibration grid, to occur in the field of view. In this work, we explore the application of a deep convolutional neural network, trained on natural images obtained from Internet photo collections, to directly estimate the focal length using only raw pixel intensities as input features.
    
    (continued)
    
</p>

<footer>
    
    <ul>
        
        <li><a href="pdfs/workman2015deepfocal.pdf">[pdf]</a></li>
        
    </ul>
    

    <p>
        submitted 
        <time datetime="2015-06-28T00:00:00Z">
            2015-06-28
        </time>
        in <a href="https://connorgreenwell.github.io/publications">publications</a>
    </p>
</footer>

</article>



<hr>




<article class="publications">

<header>
    <h1>
        <a href="https://connorgreenwell.github.io/publications/geofacial/">Large-Scale Geo-Facial Image Analysis</a>
        (In EURASIP.)
    </h1>
</header>


<figure>
    <img src="https://connorgreenwell.github.io//img/geofaces/overview.jpg">
</figure>


<p>
    Abstract While face analysis from images is a well-studied area, little work has explored the dependence of facial appearance on the geographic location from which the image was captured. To fill this gap, we constructed GeoFaces, a large dataset of geotagged face images, and used it to examine the geo-dependence of facial features and attributes, such as ethnicity, gender, or the presence of facial hair. Our analysis illuminates the relationship between raw facial appearance, facial attributes, and geographic location, both globally and in selected major urban areas.
    
    (continued)
    
</p>

<footer>
    
    <ul>
        
        <li><a href="pdfs/islam2015geofacial.pdf">[pdf]</a></li>
        
        <li><a href="http://geofaces.csr.uky.edu/">[website]</a></li>
        
    </ul>
    

    <p>
        submitted 
        <time datetime="2015-06-28T00:00:00Z">
            2015-06-28
        </time>
        in <a href="https://connorgreenwell.github.io/publications">publications</a>
    </p>
</footer>

</article>






<footer>
<hr>
<small>
	Â© Copyright 2017, Connor Greenwell
</small>
</footer>

<script src="https://connorgreenwell.github.io/js/prism.js"></script>

</body>
</html>

