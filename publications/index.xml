<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publications on Connor Greenwell</title>
    <link>https://connorgreenwell.github.io/publications/index.xml</link>
    <description>Recent content in Publications on Connor Greenwell</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Jun 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://connorgreenwell.github.io/publications/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>A Fast Method for Estimating Transient Scene Attributes</title>
      <link>https://connorgreenwell.github.io/publications/deeptransient/</link>
      <pubDate>Tue, 28 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://connorgreenwell.github.io/publications/deeptransient/</guid>
      <description>

&lt;figure&gt;
    &lt;img src=&#34;https://connorgreenwell.github.io/img/deeptransient/cartoon.png&#34;&gt;
&lt;/figure&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;We propose to use deep convolutional neural networks to estimate the transient
attributes of a scene from a single image. Transient scene attributes describe
both the objective conditions, such as the weather, time of day, and the
season, and subjective properties of a scene, such as whether or not the scene
seems busy. Recently, convolutional neural networks have been used to achieve
state-of-the-art results for many vision problems, from object detection to
scene classification, but have not previously been used for estimating
transient attributes. We compare several methods for adapting an existing
network architecture and present state-of-the-art results on two benchmark
datasets. Our method is more accurate and significantly faster than all
previous methods, enabling real-world applications.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DeepFocal: A Method for Direct Focal Length Estimation</title>
      <link>https://connorgreenwell.github.io/publications/deepfocal/</link>
      <pubDate>Sun, 28 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://connorgreenwell.github.io/publications/deepfocal/</guid>
      <description>

&lt;figure&gt;
    &lt;img src=&#34;https://connorgreenwell.github.io/img/deepfocal/cartoon.png&#34;&gt;
&lt;/figure&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;Estimating the focal length of an image is an important preprocessing step for
many applications. Despite this, existing methods for single-view focal length
estimation are limited in that they require particular geometric calibration
objects, such as orthogonal vanishing points, co-planar circles, or a
calibration grid, to occur in the field of view. In this work, we explore the
application of a deep convolutional neural network, trained on natural images
obtained from Internet photo collections, to directly estimate the focal length
using only raw pixel intensities as input features. We present quantitative
results that demonstrate the ability of our technique to estimate the focal
length with comparisons against several baseline methods, including an
automatic method which uses orthogonal vanishing points.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Large-Scale Geo-Facial Image Analysis</title>
      <link>https://connorgreenwell.github.io/publications/geofacial/</link>
      <pubDate>Sun, 28 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://connorgreenwell.github.io/publications/geofacial/</guid>
      <description>

&lt;figure&gt;
    &lt;img src=&#34;https://connorgreenwell.github.io/img/geofaces/overview.jpg&#34;&gt;
&lt;/figure&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;While face analysis from images is a well-studied area, little work has
explored the dependence of facial appearance on the geographic location from
which the image was captured. To fill this gap, we constructed GeoFaces, a
large dataset of geotagged face images, and used it to examine the
geo-dependence of facial features and attributes, such as ethnicity, gender, or
the presence of facial hair. Our analysis illuminates the relationship between
raw facial appearance, facial attributes, and geographic location, both
globally and in selected major urban areas. Some of our experiments, and the
resulting visualizations, confirm prior expectations, such as the predominance
of ethnically Asian faces in Asia, while others highlight novel information
that can be obtained with this type of analysis, such as the major city with
the highest percentage of people with a mustache.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GeoFaceExplorer: Exploring the Geo-Dependence of Facial Attributes</title>
      <link>https://connorgreenwell.github.io/publications/geofaceexplorer/</link>
      <pubDate>Sat, 28 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://connorgreenwell.github.io/publications/geofaceexplorer/</guid>
      <description>

&lt;figure&gt;
    &lt;img src=&#34;https://connorgreenwell.github.io/img/geofaces/world-beard-grid.png&#34;&gt;
&lt;/figure&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;The images uploaded to social networking websites are a rich source of
information about the appearance of people around the world. We present a
system, GeoFaceExplorer, for collecting, processing, browsing, and analyzing
this data. GeoFaceExplorer allows for the crowdsourced collection of human
facial images, as well as automated and interactive visual analysis of the
geo-dependence of facial appearance and visual attributes, such as ethnicity,
gender, and whether or not a person is wearing glasses. As a case study,
automated approaches are applied to detect common facial attributes in a large
set of geo-tagged human faces, leading to several analysis results that
illuminate the relationship between raw facial appearance, facial attributes,
and geographic location.  We show how the distribution of these attributes
differs in ten major urban areas. Our analysis also shows a similar expected
distribution of ethnicity within large urban areas in comparison to manually
collected U.S. census data. In addition, by applying automated hierarchical
clustering to facial attribute similarity, we find a large degree of overlap
between discovered regional clusters and geographical and national boundaries.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>